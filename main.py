import os
import torch
import cv2
import numpy as np
from ultralytics import YOLO  
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse, FileResponse
from pyngrok import ngrok
import uvicorn
from schemas import Prediction, BoundingBox
import aiofiles

# Kh·ªüi t·∫°o FastAPI
app = FastAPI()

# C·∫•u h√¨nh Ngrok
NGROK_AUTH_TOKEN = "2tcouva4KHG2fccLtZPW7PDXMvZ_4YCgrCFDUKea2cJUhYj8t"  # üî• Thay b·∫±ng token c·ªßa b·∫°n
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh YOLOv8
MODEL_DIR = "/content/models"
os.makedirs(MODEL_DIR, exist_ok=True)
MODEL_PATH = os.path.join(MODEL_DIR, "best (3).pt")

# Ki·ªÉm tra m√¥ h√¨nh
if not os.path.exists(MODEL_PATH):
    raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y file {MODEL_PATH}")

# Load m√¥ h√¨nh YOLOv8
print(f"üîÑ ƒêang t·∫£i m√¥ h√¨nh YOLOv8 t·ª´ {MODEL_PATH}...")
model = YOLO(MODEL_PATH)
print("‚úÖ M√¥ h√¨nh YOLOv8 ƒë√£ s·∫µn s√†ng!")

@app.post("/predict/")
async def predict_image(file: UploadFile = File(...)):
    """Nh·∫≠n ·∫£nh t·ª´ ng∆∞·ªùi d√πng, ch·∫°y YOLOv8 v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ JSON"""
    # ƒê·ªçc file ·∫£nh t·ª´ request
    image_bytes = await file.read()
    image_np = np.frombuffer(image_bytes, np.uint8)
    image = cv2.imdecode(image_np, cv2.IMREAD_COLOR)

    # Ch·∫°y m√¥ h√¨nh YOLOv8
    results = model(source=image)

    # L·∫•y danh s√°ch v·∫≠t th·ªÉ nh·∫≠n di·ªán ƒë∆∞·ª£c
    predictions = []
    for result in results:
        for i in range(len(result.boxes)):
            x1, y1, x2, y2 = result.boxes.xyxy[i].tolist()
            score = result.boxes.conf[i].item()
            label = int(result.boxes.cls[i].item())

            # T·∫°o ƒë·ªëi t∆∞·ª£ng Prediction
            prediction = Prediction(
                label=model.names[label],
                confidence=round(score, 2),
                bbox=BoundingBox(x1=int(x1), y1=int(y1), x2=int(x2), y2=int(y2))
            )
            predictions.append(prediction)

    return JSONResponse({"predictions": predictions})

@app.post("/predict-image/")
async def predict_and_return_image(file: UploadFile = File(...)):
    """Nh·∫≠n ·∫£nh t·ª´ ng∆∞·ªùi d√πng, ch·∫°y YOLOv8 v√† tr·∫£ v·ªÅ ·∫£nh c√≥ bounding box"""
    # ƒê·ªçc file ·∫£nh t·ª´ request
    image_bytes = await file.read()
    image_np = np.frombuffer(image_bytes, np.uint8)
    image = cv2.imdecode(image_np, cv2.IMREAD_COLOR)

    # Ch·∫°y m√¥ h√¨nh YOLOv8 v√† v·∫Ω bounding boxes
    results = model(source=image)
    for result in results:
        image_with_boxes = result.plot()  # V·∫Ω l√™n ·∫£nh

    # L∆∞u ·∫£nh k·∫øt qu·∫£
    output_path = "output.jpg"
    cv2.imwrite(output_path, image_with_boxes)

    # Tr·∫£ v·ªÅ ·∫£nh ƒë√£ x·ª≠ l√Ω
    return FileResponse(output_path, media_type="image/jpeg")

@app.post("/predict-video/")
async def predict_video(file: UploadFile = File(...)):
    """Nh·∫≠n video t·ª´ ng∆∞·ªùi d√πng, x·ª≠ l√Ω t·ª´ng 5 frame v√† tr·∫£ v·ªÅ video c√≥ bounding box"""

    # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
    if not file.filename.endswith((".mp4", ".avi", ".mov")):
        return JSONResponse({"error": "Ch·ªâ h·ªó tr·ª£ file video (.mp4, .avi, .mov)!"}, status_code=400)

    # Ghi file video ƒë·∫ßu v√†o
    input_video_path = "temp_input.mp4"
    async with aiofiles.open(input_video_path, "wb") as f:
        await f.write(await file.read())

    # Ki·ªÉm tra file ƒë√£ l∆∞u th√†nh c√¥ng ch∆∞a
    if not os.path.exists(input_video_path):
        return JSONResponse({"error": "Kh√¥ng th·ªÉ l∆∞u file video!"}, status_code=500)

    # M·ªü video b·∫±ng OpenCV
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened():
        return JSONResponse({"error": "Kh√¥ng th·ªÉ m·ªü video! Ki·ªÉm tra l·∫°i file ho·∫∑c codec."}, status_code=400)

    # L·∫•y th√¥ng tin video
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # T·∫°o b·ªô ghi video ƒë·∫ßu ra
    output_video_path = "output_video.mp4"
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")  # Codec MP4
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break  # H·∫øt video

        frame_count += 1

        # Ch·ªâ x·ª≠ l√Ω m·ªói 5 frame
        if frame_count % 5 == 0:
            results = model(frame)
            if results and len(results) > 0:
                frame = results[0].plot()  # plot() thay th·∫ø render() trong YOLOv8
        # Ghi frame v√†o video ƒë·∫ßu ra
        out.write(frame)

    # ƒê√≥ng video
    cap.release()
    out.release()
    os.remove(input_video_path)  # X√≥a video g·ªëc sau khi x·ª≠ l√Ω

    # Tr·∫£ v·ªÅ video ƒë√£ x·ª≠ l√Ω
    return FileResponse(output_video_path, media_type="video/mp4", filename="processed_video.mp4")

# Kh·ªüi ch·∫°y FastAPI + Ngrok
def start_ngrok():
    public_url = ngrok.connect(8000).public_url
    print(f"üî• Ngrok URL: {public_url}")

if __name__ == "__main__":
    start_ngrok()  # Ch·∫°y Ngrok
    uvicorn.run(app, host="0.0.0.0", port=8000)